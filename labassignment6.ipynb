{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment 6: Creating and Connecting to Databases\n",
    "## DS 6001: Practice and Application of Data Science\n",
    "\n",
    "### Instructions\n",
    "Please answer the following questions as completely as possible using text, code, and the results of code as needed. Format your answers in a Jupyter notebook. To receive full credit, make sure you address every part of the problem, and make sure your document is formatted in a clean and professional way.\n",
    "\n",
    "**Please note: you will not be able to use Rivanna for this lab as Rivanna is not set up to work with Docker or with Databases. If you need help getting your local system running, please let me know.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 0 [No points, no need to write anything here for any of the following parts, but do it anyway!]\n",
    "Databases require a lot of external software. The good news is that there are excellent free and open source options to do very advanced work with databases. The bad news is that each piece of additional software comes with its own complications. This problem will guide you through the installation steps for the software you need to run database systems on your computer, document those databases, and connect to them through Python with (fingers crossed) as few problems as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a\n",
    "Use `pip` to install the following Python packages on your system:\n",
    "```\n",
    "mysql-connector-python\n",
    "psycopg\n",
    "pymongo\n",
    "sqlalchemy\n",
    "wget\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part b\n",
    "With the exception of SQlite, database systems run as external software that must be installed and run on your computer. To make the installation steps easier, you will need some configuration files that I wrote and saved in a GitHub repository. Open your terminal and use the `cd` command to navigate to the folder in your computer where you want to work. Then type\n",
    "```\n",
    "git clone https://github.com/jkropko/ds6001databases\n",
    "```\n",
    "If this command works, it will create a new directory within your current folder called \"ds6001databases\".\n",
    "\n",
    "* Check that this folder exists and contains the following files: LICENSE, README.md, compose.yaml, db_tests.ipynb, and requirements.txt\n",
    "* Save the notebook file you will be using for your Lab 6 work inside the \"ds6001databases\" folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part c\n",
    "We will be using a system called Docker to work with databases. Docker is the most commonly used platform for working with **containers**. While we will not be delving into the topic of containerization in this course, a container is space in your computer's memory that is set apart from the rest of your computer. We can act as if the container is an entirely new computer, and inside the container we can change the operating system and install other software external to Python, such as database management systems. We can use a container to run Windows on a Mac, or vice versa, or Linux on any system. By far the easiest way to run MySQL, PostgreSQL, and MongoDB is through Docker containers. \n",
    "\n",
    "You will need to install Docker Desktop on your computer. Go to https://www.docker.com/products/docker-desktop/ and click on the Download button, making sure the operating system listed matches the operating system of your computer.\n",
    "\n",
    "Once Docker Desktop is installed, find the Docker Desktop program on your computer and run it.\n",
    "\n",
    "To confirm that Docker Desktop is running, open a terminal and type `docker help`. If you see documentation that begins\n",
    "```\n",
    "Usage:  docker [OPTIONS] COMMAND\n",
    "\n",
    "A self-sufficient runtime for containers\n",
    "```\n",
    "then you are all set. If you see an error that Docker is not found, then the Docker Desktop client was not installed properly, so you should try downloading and installing it from the website again. If you receive a message that the Docker daemon is not running, then Docker is installed but is not running. Find the Docker Desktop executable on your computer and click it to get Docker running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part d\n",
    "Inside your \"ds6001databases\" folder, create a .env file. On a Mac, type `touch .env` then `open .env` to create and open the file. On Windows, open a new file on Notepad and go to \"Save As\", then save it in your \"ds6001databases\" folder -- make sure to set \"File As Type\" to \"All files\" and name the file \".env\".\n",
    "\n",
    "Inside the .env file you need to choose passwords for the MySQL, PostgreSQL, and MongoDB databases, so type\n",
    "```\n",
    "MYSQL_ROOT_PASSWORD=redlobstercheddarbiscuits\n",
    "POSTGRES_PASSWORD=outbackbloominonion\n",
    "MONGO_INITDB_ROOT_PASSWORD=olivegardenunlimitedbreadsticks\n",
    "MONGO_INITDB_ROOT_USERNAME=mongo\n",
    "mongo_init_db = mongodb\n",
    "MYSQL_DATABASE=mysql\n",
    "```\n",
    "Change the passwords on the first three lines to whatever you want, but DON'T USE THE @ SYMBOL as that will cause problems. Leave the fourth, fifth, and sixth lines alone, as well as the names of each environmental variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part e\n",
    "In the terminal, make sure you are in the \"ds6001databases\" folder (you can check by typing `pwd`. If not, then use `cd` to navigate to the \"ds6001databases\" folder). Then type\n",
    "```\n",
    "docker compose up\n",
    "```\n",
    "This command launches all of the databases. If successful, you will see a long stream of output with messages that begin `ds6001databases-postgres-1`, `ds6001databases-mysql-1`, and `ds6001databases-mongo-1`. If not, we will need to debug together, but the issue likely has to do with something preventing parts a, b, c, or d from being completed successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part f\n",
    "To confirm that the databases are running on your system, open the \"db_tests.ipynb\" notebook file, which should be saved in you \"ds6001databases\" folder. Run everything in this notebook and make sure there are no errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part g\n",
    "In addition to the databases, we will be using dbdocs.io to create documentation for our databases and post them online with a stable URL. But to get dbdocs running, you first need to install NodeJS on your computer: https://nodejs.org/en\n",
    "\n",
    "Then to install dbdocs, follow the instructions here: https://dbdocs.io/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part h\n",
    "Finally, create a notebook inside your \"ds6001databases\" folder for your work on this lab. Import the following libraries, and load the `.env` file where you store your passwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wget\n",
    "import sqlite3\n",
    "import sqlalchemy\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import dotenv\n",
    "import mysql.connector\n",
    "import psycopg\n",
    "import pymongo\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "dotenv.load_dotenv()\n",
    "POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "MONGO_INITDB_ROOT_USERNAME = os.getenv('MONGO_INITDB_ROOT_USERNAME')\n",
    "MONGO_INITDB_ROOT_PASSWORD = os.getenv('MONGO_INITDB_ROOT_PASSWORD')\n",
    "mongo_init_db = os.getenv('mongo_init_db')\n",
    "MYSQL_ROOT_PASSWORD = os.getenv('MYSQL_ROOT_PASSWORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 \n",
    "**This problem requires you to create Markdown tables** \n",
    "\n",
    "To create a table in a markdown cell, I recommend using the markdown table generator here: https://www.tablesgenerator.com/markdown_tables. This interface allows you to choose the number of rows and columns, fill in those rows and colums, and push the \"generate\" button. The website will display markdown table code that looks like:\n",
    "```\n",
    "| Day       | Temp | Rain |\n",
    "|-----------|------|------|\n",
    "| Monday    | 74   | No   |\n",
    "| Tuesday   | 58   | Yes  |\n",
    "| Wednesday | 76   | No   |\n",
    "```\n",
    "Copy the markdown code and paste it into a markdown cell in your notebook. Markdown will read the code and display a table that looks like this:\n",
    "\n",
    "| Day       | Temp | Rain |\n",
    "|-----------|------|------|\n",
    "| Monday    | 74   | No   |\n",
    "| Tuesday   | 58   | Yes  |\n",
    "| Wednesday | 76   | No   |\n",
    "\n",
    "Suppose that we have (fake) data on people who were hospitalized and received at least one prescription for a medication. Here are ten records in the data:\n",
    "\n",
    "(If this table gets cut off in the PDF, please look at the .ipynb notebook file on the module 6 page on Canvas)\n",
    "\n",
    "| patient_name       | date_of_birth | prescribed_drug | prior_conditions                     | patient_sex | patient_insurance      | drug_maker               | drug_cost | attending_physician | AP_medschool                      | AP_years_experience | hospital                       | hospital_location |\n",
    "|--------------------|---------------|-----------------|--------------------------------------|-------------|------------------------|--------------------------|-----------|---------------------|-----------------------------------|--------------------|--------------------------------|-------------------|\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Amoxil          | [Pneumonia, Diabetes]                | M           | Aetna                  | USAntibiotics            | 14.62     | Earnest Caro        | University of California (Irvine) | 14                 | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Micronase       | [Pneumonia, Diabetes]                | M           | Aetna                  | Pfizer                   | 20.55     | Earnest Caro        | University of California (Irvine) | 14                 | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| Raniero Coumans    | 8/15/1990     | Zosyn           | [Appendicitis, Crohn's disease]      | M           | Cigna                  | Baxter International Inc | 394.00    | Pamela English      | University of Michigan            | 29                 | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| Raniero Coumans    | 8/15/1990     | Humira          | [Appendicitis, Crohn's disease]      | M           | Cigna                  | Abbvie                   | 7000.00   | Pamela English      | University of Michigan            | 29                 | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| Mizuki Debenham    | 3/12/1977     | Inlyta          | [Kidney Cancer]                      | F           | Kaiser Permanente      | Pfizer                   | 21644.00  | Lewis Conti         | North Carolina State University   | 8                  | Houston Methodist Hospital     | Houston, TX       |\n",
    "| Zoë De Witt        | 11/23/1947    | Atenolol        | [Cardiomyopathy, Diabetes, Sciatica] | F           | Medicare               | Mylan Pharmaceuticals    | 10.58     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| Zoë De Witt        | 11/23/1947    | Micronase       | [Cardiomyopathy, Diabetes, Sciatica] | F           | Medicare               | Pfizer                   | 20.55     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| Zoë De Witt        | 11/23/1947    | Demerol         | [Cardiomyopathy, Diabetes, Sciatica] | F           | Medicare               | Pfizer                   | 37.50     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| Bonnie Hooper      | 7/4/1951      | Xeloda          | [Pancreatic Cancer, Sciatica]        | F           | Blue Cross Blue Shield | Genentech                | 860.00    | Steven Garbutt      | Ohio State University             | 36                 | UCSF Medical Center            | San Francisco, CA |\n",
    "| Bonnie Hooper      | 7/4/1951      | Demerol         | [Pancreatic Cancer, Sciatica]        | F           | Blue Cross Blue Shield | Pfizer                   | 37.50     | Steven Garbutt      | Ohio State University             | 36                 | UCSF Medical Center            | San Francisco, CA |\n",
    "\n",
    "The columns in this dataset are:\n",
    "\n",
    "* **patient_name**: The patient's name\n",
    "* **date_of_birth**: The patient's date of birth\n",
    "* **prescribed_drug**: The brand name of the medication that patient has been prescribed\n",
    "* **prior_conditions**: A list of the conditions that the patient had been diagnosed with prior to the patient's hospitalization\n",
    "* **patient_sex**: The patient's sex\n",
    "* **patient_insurance**: The company responsible for the patient's health insurance coverage\n",
    "* **drug_maker**: The company that manufactures the prescribed drug\n",
    "* **drug_cost**: The cost of the prescribed drug\n",
    "* **attending_physician**: The name of the attending physician for the patient\n",
    "* **AP_medschool**: The name of the school where the attending physician got a medical degree\n",
    "* **AP_years_experience**: The attending physician's number of years of experience post-residency\n",
    "* **hospital**: The hospital where the attending physicial is employed\n",
    "* **hospital_location**: The location of the hospital\n",
    "\n",
    "For this problem, assume that \n",
    "\n",
    "1. No two rows in this table share both the same patient and the same prescribed drug.\n",
    "   \n",
    "2. Some patients in the data share the same name, but no two patients in the data share the same name and date of birth.\n",
    "\n",
    "3. No two different drugs share the same brand name.\n",
    "\n",
    "4. No two attending physicians have the same name, and every attending physician is employed at only one hospital.\n",
    "\n",
    "5. No two hospitals share the same name, and every hospital exists at only one location.\n",
    "   \n",
    "6. Each patient has only one attending physician. (In real-world applications we may want to design a database that allows for multiple hospitalizations for some patients, but here we'll keep it simpler by assuming each patient has one hospitalization with one attending physician.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a \n",
    "Rearrange the data into a group of data tables that together meet the requirements of first normal form. [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| patient_id | patient_name       | date_of_birth | patient_sex | patient_insurance      |\n",
    "|------------|--------------------|---------------|-------------|------------------------|\n",
    "| 1          | Nkemdilim Arendonk | 2/21/1962     | M           | Aetna                  |\n",
    "| 2          | Raniero Coumans    | 8/15/1990     | M           | Cigna                  |\n",
    "| 3          | Mizuki Debenham    | 3/12/1977     | F           | Kaiser Permanente      |\n",
    "| 4          | Zoë De Witt        | 11/23/1947    | F           | Medicare               |\n",
    "| 5          | Bonnie Hooper      | 7/4/1951      | F           | Blue Cross Blue Shield |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| drug_id | prescribed_drug | drug_maker               | drug_cost |\n",
    "|---------|-----------------|--------------------------|-----------|\n",
    "| 1       | Amoxil          | USAntibiotics            | 14.62     |\n",
    "| 2       | Micronase       | Pfizer                   | 20.55     |\n",
    "| 3       | Zosyn           | Baxter International Inc | 394.00    |\n",
    "| 4       | Humira          | Abbvie                   | 7000.00   |\n",
    "| 5       | Inlyta          | Pfizer                   | 21644.00  |\n",
    "| 6       | Atenolol        | Mylan Pharmaceuticals    | 10.58     |\n",
    "| 7       | Demerol         | Pfizer                   | 37.50     |\n",
    "| 8       | Xeloda          | Genentech                | 860.00    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| condition_id | condition          |\n",
    "|--------------|--------------------|\n",
    "| 1            | Pneumonia          |\n",
    "| 2            | Diabetes           |\n",
    "| 3            | Appendicitis       |\n",
    "| 4            | Crohn's disease    |\n",
    "| 5            | Kidney Cancer      |\n",
    "| 6            | Cardiomyopathy     |\n",
    "| 7            | Sciatica           |\n",
    "| 8            | Pancreatic Cancer  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| patient_id | condition_id |\n",
    "|------------|--------------|\n",
    "| 1          | 1            |\n",
    "| 1          | 2            |\n",
    "| 2          | 3            |\n",
    "| 2          | 4            |\n",
    "| 3          | 5            |\n",
    "| 4          | 6            |\n",
    "| 4          | 2            |\n",
    "| 4          | 7            |\n",
    "| 5          | 8            |\n",
    "| 5          | 7            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| physician_id | attending_physician | AP_medschool                      | AP_years_experience |\n",
    "|--------------|---------------------|-----------------------------------|---------------------|\n",
    "| 1            | Earnest Caro        | University of California (Irvine) | 14                  |\n",
    "| 2            | Pamela English      | University of Michigan            | 29                  |\n",
    "| 3            | Lewis Conti         | North Carolina State University   | 8                   |\n",
    "| 4            | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                  |\n",
    "| 5            | Steven Garbutt      | Ohio State University             | 36                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| hospital_id | hospital                       | hospital_location |\n",
    "|-------------|--------------------------------|-------------------|\n",
    "| 1           | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| 2           | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| 3           | Houston Methodist Hospital     | Houston, TX       |\n",
    "| 4           | Mount Sinai Hospital           | New York, NY      |\n",
    "| 5           | UCSF Medical Center            | San Francisco, CA |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| prescription_id | patient_id | drug_id | physician_id | hospital_id |\n",
    "|-----------------|------------|---------|--------------|-------------|\n",
    "| 1               | 1          | 1       | 1            | 1           |\n",
    "| 2               | 1          | 2       | 1            | 1           |\n",
    "| 3               | 2          | 3       | 2            | 2           |\n",
    "| 4               | 2          | 4       | 2            | 2           |\n",
    "| 5               | 3          | 5       | 3            | 3           |\n",
    "| 6               | 4          | 6       | 4            | 4           |\n",
    "| 7               | 4          | 2       | 4            | 4           |\n",
    "| 8               | 4          | 7       | 4            | 4           |\n",
    "| 9               | 5          | 8       | 5            | 5           |\n",
    "| 10              | 5          | 7       | 5            | 5           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part b \n",
    "Rearrange the data on the five patients into a group of data tables that together meet the requirements of second normal form. [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| patient_id | patient_name       | date_of_birth | patient_sex | patient_insurance      |\n",
    "|------------|--------------------|---------------|-------------|------------------------|\n",
    "| 1          | Nkemdilim Arendonk | 1962-02-21    | M           | Aetna                  |\n",
    "| 2          | Raniero Coumans    | 1990-08-15    | M           | Cigna                  |\n",
    "| 3          | Mizuki Debenham    | 1977-03-12    | F           | Kaiser Permanente      |\n",
    "| 4          | Zoë De Witt        | 1947-11-23    | F           | Medicare               |\n",
    "| 5          | Bonnie Hooper      | 1951-07-04    | F           | Blue Cross Blue Shield |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| drug_id | prescribed_drug | drug_maker               | drug_cost |\n",
    "|---------|-----------------|--------------------------|-----------|\n",
    "| 1       | Amoxil          | USAntibiotics            | 14.62     |\n",
    "| 2       | Micronase       | Pfizer                   | 20.55     |\n",
    "| 3       | Zosyn           | Baxter International Inc | 394.00    |\n",
    "| 4       | Humira          | Abbvie                   | 7000.00   |\n",
    "| 5       | Inlyta          | Pfizer                   | 21644.00  |\n",
    "| 6       | Atenolol        | Mylan Pharmaceuticals    | 10.58     |\n",
    "| 7       | Demerol         | Pfizer                   | 37.50     |\n",
    "| 8       | Xeloda          | Genentech                | 860.00    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| condition_id | condition          |\n",
    "|--------------|--------------------|\n",
    "| 1            | Pneumonia          |\n",
    "| 2            | Diabetes           |\n",
    "| 3            | Appendicitis       |\n",
    "| 4            | Crohn's disease    |\n",
    "| 5            | Kidney Cancer      |\n",
    "| 6            | Cardiomyopathy     |\n",
    "| 7            | Sciatica           |\n",
    "| 8            | Pancreatic Cancer  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| patient_id | condition_id |\n",
    "|------------|--------------|\n",
    "| 1          | 1            |\n",
    "| 1          | 2            |\n",
    "| 2          | 3            |\n",
    "| 2          | 4            |\n",
    "| 3          | 5            |\n",
    "| 4          | 6            |\n",
    "| 4          | 2            |\n",
    "| 4          | 7            |\n",
    "| 5          | 8            |\n",
    "| 5          | 7            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| physician_id | attending_physician | AP_medschool                      | AP_years_experience |\n",
    "|--------------|---------------------|-----------------------------------|---------------------|\n",
    "| 1            | Earnest Caro        | University of California (Irvine) | 14                  |\n",
    "| 2            | Pamela English      | University of Michigan            | 29                  |\n",
    "| 3            | Lewis Conti         | North Carolina State University   | 8                   |\n",
    "| 4            | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                  |\n",
    "| 5            | Steven Garbutt      | Ohio State University             | 36                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| hospital_id | hospital                       | hospital_location |\n",
    "|-------------|--------------------------------|-------------------|\n",
    "| 1           | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| 2           | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| 3           | Houston Methodist Hospital     | Houston, TX       |\n",
    "| 4           | Mount Sinai Hospital           | New York, NY      |\n",
    "| 5           | UCSF Medical Center            | San Francisco, CA |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| prescription_id | patient_id | drug_id | physician_id | hospital_id |\n",
    "|-----------------|------------|---------|--------------|-------------|\n",
    "| 1               | 1          | 1       | 1            | 1           |\n",
    "| 2               | 1          | 2       | 1            | 1           |\n",
    "| 3               | 2          | 3       | 2            | 2           |\n",
    "| 4               | 2          | 4       | 2            | 2           |\n",
    "| 5               | 3          | 5       | 3            | 3           |\n",
    "| 6               | 4          | 6       | 4            | 4           |\n",
    "| 7               | 4          | 2       | 4            | 4           |\n",
    "| 8               | 4          | 7       | 4            | 4           |\n",
    "| 9               | 5          | 8       | 5            | 5           |\n",
    "| 10              | 5          | 7       | 5            | 5           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part c \n",
    "Rearrange the data into a group of data tables that together meet the requirements of third normal form. [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| patient_id | patient_name       | date_of_birth | patient_sex | patient_insurance      |\n",
    "|------------|--------------------|---------------|-------------|------------------------|\n",
    "| 1          | Nkemdilim Arendonk | 1962-02-21    | M           | Aetna                  |\n",
    "| 2          | Raniero Coumans    | 1990-08-15    | M           | Cigna                  |\n",
    "| 3          | Mizuki Debenham    | 1977-03-12    | F           | Kaiser Permanente      |\n",
    "| 4          | Zoë De Witt        | 1947-11-23    | F           | Medicare               |\n",
    "| 5          | Bonnie Hooper      | 1951-07-04    | F           | Blue Cross Blue Shield |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| drug_id | prescribed_drug | drug_maker               | drug_cost |\n",
    "|---------|-----------------|--------------------------|-----------|\n",
    "| 1       | Amoxil          | USAntibiotics            | 14.62     |\n",
    "| 2       | Micronase       | Pfizer                   | 20.55     |\n",
    "| 3       | Zosyn           | Baxter International Inc | 394.00    |\n",
    "| 4       | Humira          | Abbvie                   | 7000.00   |\n",
    "| 5       | Inlyta          | Pfizer                   | 21644.00  |\n",
    "| 6       | Atenolol        | Mylan Pharmaceuticals    | 10.58     |\n",
    "| 7       | Demerol         | Pfizer                   | 37.50     |\n",
    "| 8       | Xeloda          | Genentech                | 860.00    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| condition_id | condition          |\n",
    "|--------------|--------------------|\n",
    "| 1            | Pneumonia          |\n",
    "| 2            | Diabetes           |\n",
    "| 3            | Appendicitis       |\n",
    "| 4            | Crohn's disease    |\n",
    "| 5            | Kidney Cancer      |\n",
    "| 6            | Cardiomyopathy     |\n",
    "| 7            | Sciatica           |\n",
    "| 8            | Pancreatic Cancer  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| patient_id | condition_id |\n",
    "|------------|--------------|\n",
    "| 1          | 1            |\n",
    "| 1          | 2            |\n",
    "| 2          | 3            |\n",
    "| 2          | 4            |\n",
    "| 3          | 5            |\n",
    "| 4          | 6            |\n",
    "| 4          | 2            |\n",
    "| 4          | 7            |\n",
    "| 5          | 8            |\n",
    "| 5          | 7            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| physician_id | attending_physician | AP_medschool_id |\n",
    "|--------------|---------------------|-----------------|\n",
    "| 1            | Earnest Caro        | 1               |\n",
    "| 2            | Pamela English      | 2               |\n",
    "| 3            | Lewis Conti         | 3               |\n",
    "| 4            | Theresa Dahlmans    | 4               |\n",
    "| 5            | Steven Garbutt      | 5               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| hospital_id | hospital                       | hospital_location |\n",
    "|-------------|--------------------------------|-------------------|\n",
    "| 1           | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| 2           | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| 3           | Houston Methodist Hospital     | Houston, TX       |\n",
    "| 4           | Mount Sinai Hospital           | New York, NY      |\n",
    "| 5           | UCSF Medical Center            | San Francisco, CA |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| prescription_id | patient_id | drug_id | physician_id | hospital_id |\n",
    "|-----------------|------------|---------|--------------|-------------|\n",
    "| 1               | 1          | 1       | 1            | 1           |\n",
    "| 2               | 1          | 2       | 1            | 1           |\n",
    "| 3               | 2          | 3       | 2            | 2           |\n",
    "| 4               | 2          | 4       | 2            | 2           |\n",
    "| 5               | 3          | 5       | 3            | 3           |\n",
    "| 6               | 4          | 6       | 4            | 4           |\n",
    "| 7               | 4          | 2       | 4            | 4           |\n",
    "| 8               | 4          | 7       | 4            | 4           |\n",
    "| 9               | 5          | 8       | 5            | 5           |\n",
    "| 10              | 5          | 7       | 5            | 5           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "For this problem, create ER diagrams of the database you created in problem 1, part c using https://dbdocs.io/. Make sure you install DBDocs on your system by following these instructions: https://dbdocs.io/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a \n",
    "Write code using the [database markup language](https://dbml.dbdiagram.io/home/) (DBML) that represents all of the tables in this database and the connections between the tables. Paste your DBML code in a markdown cell in your notebook, contained within three backticks to begin and end the code snippet, as shown in the cell below. \n",
    "\n",
    "Two good resources to help you:\n",
    "\n",
    "1. The example on the Getting Started page on dbdocs.io: https://dbdocs.io/docs\n",
    "2. The full syntax guide for DBML: https://dbml.dbdiagram.io/docs/#project-definition\n",
    "\n",
    "A few notes:\n",
    "* Make sure to specify the data type for each column in each table. Use varchar for strings/text, int for integers, and float for numeric data with decimals.\n",
    "* You will probably find it useful to alias each table with one or two letters, such as: Table PRESCRIPTIONS as PR. That will allow you to use PR to refer to the PRESCRIPTIONS table, for example, in the Reference statements to link tables together.\n",
    "* Use the syntax [pk] after a column name and data type to designate the columns that are primary keys in each table.\n",
    "* To draw the lines linking one table to another, use the Ref: syntax.\n",
    "    * If many rows from the left table match to one row in the right table, use the \"many to one\" symbol >\n",
    "    * If one row from the left table matches to many rows in the right table, use the \"one to many\" symbol <\n",
    "    * If one row from the left table matches to one row in the right table, use the \"one to one\" symbol -\n",
    "    * If many rows from the left table match to many rows in the right table, use the \"many to many\" symbol <>\n",
    "      \n",
    "[2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Project Lab6 {\n",
    "  database_type: 'PostgreSQL'\n",
    "  Note: '''\n",
    "    # Lab6 Database\n",
    "    **database schema for Lab6 project.**\n",
    "  '''\n",
    "}\n",
    "\n",
    "Table patients {\n",
    "  patient_id int [pk]\n",
    "  patient_name varchar\n",
    "  date_of_birth date\n",
    "  patient_sex varchar\n",
    "  patient_insurance varchar\n",
    "}\n",
    "\n",
    "Table medications {\n",
    "  drug_id int [pk]\n",
    "  prescribed_drug varchar\n",
    "  drug_maker varchar\n",
    "  drug_cost float\n",
    "}\n",
    "\n",
    "Table conditions {\n",
    "  condition_id int [pk]\n",
    "  condition varchar\n",
    "}\n",
    "\n",
    "Table patient_conditions {\n",
    "  patient_id int\n",
    "  condition_id int\n",
    "}\n",
    "\n",
    "Table physicians {\n",
    "  physician_id int [pk]\n",
    "  attending_physician varchar\n",
    "  AP_medschool_id int\n",
    "}\n",
    "\n",
    "Table medschools {\n",
    "  medschool_id int [pk]\n",
    "  AP_medschool varchar\n",
    "  AP_years_experience int\n",
    "}\n",
    "\n",
    "Table hospitals {\n",
    "  hospital_id int [pk]\n",
    "  hospital varchar\n",
    "  hospital_location varchar\n",
    "}\n",
    "\n",
    "Table prescriptions {\n",
    "  prescription_id int [pk]\n",
    "  patient_id int\n",
    "  drug_id int\n",
    "  physician_id int\n",
    "  hospital_id int\n",
    "}\n",
    "\n",
    "Ref: patient_conditions.patient_id > patients.patient_id\n",
    "Ref: patient_conditions.condition_id > conditions.condition_id\n",
    "Ref: physicians.AP_medschool_id > medschools.medschool_id\n",
    "Ref: prescriptions.patient_id > patients.patient_id\n",
    "Ref: prescriptions.drug_id > medications.drug_id\n",
    "Ref: prescriptions.physician_id > physicians.physician_id\n",
    "Ref: prescriptions.hospital_id > hospitals.hospital_id\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b\n",
    "Use the instructions on DBDocs.io (https://dbdocs.io/docs) to create a website for your ER diagram. Type the URL for your website in a markdown cell here. [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My example is here: https://dbdocs.io/jkropko/Lab6?view=relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ER diagram for Lab6: https://dbdocs.io/qaisme100/Lab6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "For this problem, you will download the individual CSV files that comprise a relational database on album reviews from [Pitchfork Magazine](https://pitchfork.com/), collected via webscraping by [Nolan B. Conaway](https://github.com/nolanbconaway/pitchfork-data), and use them to initialize local databases using SQlite, MySQL, and PostgreSQL. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code of code will download the CSV files. Please run this as is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/nolanbconaway/pitchfork-data/raw/master/pitchfork.db\"\n",
    "pfork = wget.download(url)\n",
    "pitchfork = sqlite3.connect(pfork)\n",
    "for t in ['artists','content','genres','labels','reviews','years']:\n",
    "    datatable = pd.read_sql_query(\"SELECT * FROM {tab}\".format(tab=t), pitchfork)\n",
    "    datatable.to_csv(\"{tab}.csv\".format(tab=t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this code downloaded a SQlite database and extracted the tables, saving each one as a CSV. That seems backwards, as the purpose of this exercise is to create databases. But the point here is to practice creating databases from individual data frames. Next we load the CSVs to create the data frames in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"reviews.csv\")\n",
    "artists = pd.read_csv(\"artists.csv\")\n",
    "content = pd.read_csv(\"content.csv\")\n",
    "genres = pd.read_csv(\"genres.csv\")\n",
    "labels = pd.read_csv(\"labels.csv\")\n",
    "years = pd.read_csv(\"years.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a\n",
    "Initialize a new database using SQlite and the `sqlite3` library. Add the six dataframes to this database. Then issue the following query to the database\n",
    "```\n",
    "SELECT title, artist, score FROM reviews WHERE score=10\n",
    "```\n",
    "using two methods: first, using the `.cursor()` method, and second using `pd.read_sql_query()`. Finally, commit your changes to the database and close the database. (If you get a warning about spaces in the column names, feel free to ignore it this time.) [2 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19108"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import wget\n",
    "\n",
    "new_db = sqlite3.connect('pitchfork_a.db')\n",
    "\n",
    "reviews.to_sql('reviews', new_db, if_exists='replace', index=False)\n",
    "artists.to_sql('artists', new_db, if_exists='replace', index=False)\n",
    "content.to_sql('content', new_db, if_exists='replace', index=False)\n",
    "genres.to_sql('genres', new_db, if_exists='replace', index=False)\n",
    "labels.to_sql('labels', new_db, if_exists='replace', index=False)\n",
    "years.to_sql('years', new_db, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using .cursor() method:\n",
      "('metal box', 'public image ltd', 10.0)\n",
      "('blood on the tracks', 'bob dylan', 10.0)\n",
      "('another green world', 'brian eno', 10.0)\n",
      "('songs in the key of life', 'stevie wonder', 10.0)\n",
      "('in concert', 'nina simone', 10.0)\n",
      "(\"tonight's the night\", 'neil young', 10.0)\n",
      "('hounds of love', 'kate bush', 10.0)\n",
      "('sign \"o\" the times', 'prince', 10.0)\n",
      "('1999', 'prince', 10.0)\n",
      "('purple rain', 'prince, the revolution', 10.0)\n",
      "('dirty mind', 'prince', 10.0)\n",
      "('off the wall', 'michael jackson', 10.0)\n",
      "('\"heroes\"', 'david bowie', 10.0)\n",
      "('low', 'david bowie', 10.0)\n",
      "('a love supreme: the complete masters', 'john coltrane', 10.0)\n",
      "(\"people's instinctive travels and the paths of rhythm\", 'a tribe called quest', 10.0)\n",
      "('astral weeks', 'van morrison', 10.0)\n",
      "('loaded: re-loaded 45th anniversary edition', 'the velvet underground', 10.0)\n",
      "('sticky fingers', 'the rolling stones', 10.0)\n",
      "('it takes a nation of millions to hold us back', 'public enemy', 10.0)\n",
      "('the velvet underground  45th anniversary super deluxe edition', 'the velvet underground', 10.0)\n",
      "('spiderland', 'slint', 10.0)\n",
      "('the infamous', 'mobb deep', 10.0)\n",
      "('white light/white heat', 'the velvet underground', 10.0)\n",
      "('in utero: 20th anniversary edition', 'nirvana', 10.0)\n",
      "('rumours', 'fleetwood mac', 10.0)\n",
      "('illmatic', 'nas', 10.0)\n",
      "('donuts (45 box set)', 'j dilla', 10.0)\n",
      "('voodoo', 'dangelo', 10.0)\n",
      "('the disintegration loops', 'william basinski', 10.0)\n",
      "('liquid swords: chess box deluxe edition', 'gza', 10.0)\n",
      "(\"isn't anything\", 'my bloody valentine', 10.0)\n",
      "('tago mago [40th anniversary edition]', 'can', 10.0)\n",
      "('the smile sessions', 'the beach boys', 10.0)\n",
      "('laughing stock', 'talk talk', 10.0)\n",
      "('nevermind [20th anniversary edition]', 'nirvana', 10.0)\n",
      "('emergency & i [vinyl reissue]', 'the dismemberment plan', 10.0)\n",
      "('my beautiful dark twisted fantasy', 'kanye west', 10.0)\n",
      "('disintegration [deluxe edition]', 'the cure', 10.0)\n",
      "('exile on main st. [deluxe edition]', 'the rolling stones', 10.0)\n",
      "('quarantine the past', 'pavement', 10.0)\n",
      "(\"ladies and gentlemen we are floating in space [collector's editon]\", 'spiritualized', 10.0)\n",
      "('the stone roses', 'the stone roses', 10.0)\n",
      "('the beatles', 'the beatles', 10.0)\n",
      "('abbey road', 'the beatles', 10.0)\n",
      "('rubber soul', 'the beatles', 10.0)\n",
      "('revolver', 'the beatles', 10.0)\n",
      "(\"sgt. pepper's lonely hearts club band\", 'the beatles', 10.0)\n",
      "('magical mystery tour', 'the beatles', 10.0)\n",
      "('stereo box', 'the beatles', 10.0)\n",
      "('kid a: special collectors edition', 'radiohead', 10.0)\n",
      "('reckoning [deluxe edition]', 'r.e.m.', 10.0)\n",
      "('histoire de melody nelson', 'serge gainsbourg', 10.0)\n",
      "(\"paul's boutique\", 'beastie boys', 10.0)\n",
      "('murmur [deluxe edition]', 'r.e.m.', 10.0)\n",
      "(\"otis blue: otis redding sings soul [collector's edition]\", 'otis redding', 10.0)\n",
      "('unknown pleasures', 'joy division', 10.0)\n",
      "('daydream nation: deluxe edition', 'sonic youth', 10.0)\n",
      "('pink flag', 'wire', 10.0)\n",
      "('born to run: 30th anniversary edition', 'bruce springsteen', 10.0)\n",
      "('in the aeroplane over the sea', 'neutral milk hotel', 10.0)\n",
      "('endtroducing... [deluxe edition]', 'dj shadow', 10.0)\n",
      "(\"crooked rain, crooked rain: la's desert origins\", 'pavement', 10.0)\n",
      "('london calling: 25th anniversary legacy edition', 'the clash', 10.0)\n",
      "('music has the right to children', 'boards of canada', 10.0)\n",
      "('live at the apollo [expanded edition]', 'james brown', 10.0)\n",
      "('no thanks!: the 70s punk rebellion', 'various artists', 10.0)\n",
      "('marquee moon', 'television', 10.0)\n",
      "('the ascension', 'glenn branca', 10.0)\n",
      "(\"this year's model\", 'elvis costello & the attractions', 10.0)\n",
      "('yankee hotel foxtrot', 'wilco', 10.0)\n",
      "('source tags and codes', '...and you will know us by the trail of dead', 10.0)\n",
      "('the olatunji concert: the last live recording', 'john coltrane', 10.0)\n",
      "('kid a', 'radiohead', 10.0)\n",
      "('animals', 'pink floyd', 10.0)\n",
      "('i see a darkness', 'bonnie prince billy', 10.0)\n"
     ]
    }
   ],
   "source": [
    "cursor = new_db.cursor()\n",
    "cursor.execute(\"SELECT title, artist, score FROM reviews WHERE score=10\")\n",
    "results_cursor = cursor.fetchall()\n",
    "\n",
    "print(\"Results using .cursor() method:\")\n",
    "for row in results_cursor:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results using pd.read_sql_query():\n",
      "                                            title  \\\n",
      "0                                       metal box   \n",
      "1                             blood on the tracks   \n",
      "2                             another green world   \n",
      "3                        songs in the key of life   \n",
      "4                                      in concert   \n",
      "..                                            ...   \n",
      "71                          source tags and codes   \n",
      "72  the olatunji concert: the last live recording   \n",
      "73                                          kid a   \n",
      "74                                        animals   \n",
      "75                               i see a darkness   \n",
      "\n",
      "                                          artist  score  \n",
      "0                               public image ltd   10.0  \n",
      "1                                      bob dylan   10.0  \n",
      "2                                      brian eno   10.0  \n",
      "3                                  stevie wonder   10.0  \n",
      "4                                    nina simone   10.0  \n",
      "..                                           ...    ...  \n",
      "71  ...and you will know us by the trail of dead   10.0  \n",
      "72                                 john coltrane   10.0  \n",
      "73                                     radiohead   10.0  \n",
      "74                                    pink floyd   10.0  \n",
      "75                           bonnie prince billy   10.0  \n",
      "\n",
      "[76 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT title, artist, score FROM reviews WHERE score=10\"\n",
    "results_df = pd.read_sql_query(query, new_db)\n",
    "print(\"\\nResults using pd.read_sql_query():\")\n",
    "print(results_df)\n",
    "\n",
    "new_db.commit()\n",
    "cursor.close()\n",
    "new_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part b\n",
    "Follow the instructions in the Jupyter notebook for this module to install MySQL and `mysql.connector` on your computer. Make sure the MySQL server is running. Then import `mysql.connector` and do all of the tasks listed for part a using a MySQL database (including commiting changes and closing the database connection). Take steps to hide your password - do not let it display in your notebook. [3 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, exc\n",
    "\n",
    "load_dotenv()\n",
    "MYSQL_ROOT_PASSWORD = os.getenv('MYSQL_ROOT_PASSWORD')\n",
    "MYSQL_DATABASE = os.getenv('MYSQL_DATABASE')\n",
    "\n",
    "engine_string = f'mysql+mysqlconnector://root:{MYSQL_ROOT_PASSWORD}@localhost:3306/{MYSQL_DATABASE}'\n",
    "engine = create_engine(engine_string)\n",
    "\n",
    "reviews = pd.read_csv('reviews.csv')\n",
    "artists = pd.read_csv('artists.csv')\n",
    "content = pd.read_csv('content.csv')\n",
    "genres = pd.read_csv('genres.csv')\n",
    "labels = pd.read_csv('labels.csv')\n",
    "years = pd.read_csv('years.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading content: (mysql.connector.errors.OperationalError) 2013 (HY000): Lost connection to MySQL server during query\n",
      "[SQL: INSERT INTO content (`Unnamed: 0`, reviewid, content) VALUES (%(UnnamedC_0)s, %(reviewid)s, %(content)s)]\n",
      "[parameters: [{'UnnamedC_0': 0, 'reviewid': 22703, 'content': \"“Trip-hop” eventually became a ’90s punchline, a music-press shorthand for “overhyped hotel lounge music.” But today, the much-maligned subgenre almo ... (9090 characters truncated) ... he immediacy of its creators' tumultuous late ’90s, and fearless enough that it still sounds like it belongs in whatever timeframe you're playing it.\"}, {'UnnamedC_0': 1, 'reviewid': 22721, 'content': 'Eight years, five albums, and two EPs in, the New York-based outfit Krallice have long since shut up purists about their “hipster black metal.” Their ... (2511 characters truncated) ... ut the moment is dense and terrifying enough to make Krallice fans wonder: What could they accomplish with an album of compositions this compact?\\xa0'}, {'UnnamedC_0': 2, 'reviewid': 22659, 'content': 'Minneapolis’ Uranium Club seem to revel in being aggressively obtuse. They sprung up last year with their Human Exploration EP, an eight-song tape of ... (3291 characters truncated) ... tation. The band clearly wants to keep everyone on edge. If the Uranium Club is anything, it is at least very self-aware of exactly what it is doing.'}, {'UnnamedC_0': 3, 'reviewid': 22661, 'content': \"Kleenex began\\xa0with a crash. It transpired one night not long after they’d formed,\\xa0in Zurich of 1978, while\\xa0the germinal punk group was onsta ... (7677 characters truncated) ... idea.\\xa0First Songs\\xa0is a testament to the\\xa0freedom in limitation, or rather, the limitless nature of freedom when logic\\xa0is tossed aside.\\xa0\"}, {'UnnamedC_0': 4, 'reviewid': 22725, 'content': 'It is impossible to consider a given release by a footwork artist without confronting\\xa0the long shadow cast by DJ Rashad’s catalog, particularly hi ... (2918 characters truncated) ... entation). Still, New Start proves that the prowess of footwork’s first family is intact, and Taso might just be the glue that holds it all together.'}, {'UnnamedC_0': 5, 'reviewid': 22722, 'content': 'In the pilot episode of “Insecure,” the critically lauded HBO comedy series created by Issa Rae and Larry Wilmore, Rae’s eponymous character Issa is  ... (4058 characters truncated) ... nd season and while the protagonists’ fate is surely the highest priority for fans, a chance to devour the forthcoming score can’t be too far behind.'}, {'UnnamedC_0': 6, 'reviewid': 22704, 'content': 'Rapper Simbi Ajikawo, who records as Little Simz, is by all measures on an upward trajectory, with comparisons to iconoclasts like Lauryn Hill and pr ... (3541 characters truncated) ...  SiR says on “One in Rotation”; there’s some false dichotomy shit going on here, and then the track cuts off, abruptly, as if snapped out of a dream.'}, {'UnnamedC_0': 7, 'reviewid': 22694, 'content': 'For the last thirty years, Israel’s electronic music scene has operated in fits and starts. When India opened up their borders to Israeli passports i ... (2308 characters truncated) ... s squalls of feedback and noise that give the track some grit, so that a mix of the ancient and futuristic also has a bit of the messy present in it.'}  ... displaying 10 of 18393 total bound parameter sets ...  {'UnnamedC_0': 18391, 'reviewid': 2413, 'content': 'Well, kids, I just went back and re-read my review for these guys\\' last album,     What Burns never Returns, and what a laugh it was! Sometimes I ju ... (2154 characters truncated) ...  weirdos, I would suggest you take a large dose of Ketamine before     enjoying.  And don\\'t forget to stick a sharp, barbed object into your bottom!'}, {'UnnamedC_0': 18392, 'reviewid': 3723, 'content': 'Neil Hamburger\\'s third comedy release is a desperate affair, even for a\\n    sad sack such as America\\'s Funnyman.  Hamburger-- aka Gregg Turkington ... (1585 characters truncated) ... et the joke.  But there\\n    aren\\'t really any jokes on this album, just a series of empty shells and\\n    failed observations... classic Hamburger.'}]]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "def load_data_to_mysql(df, table_name):\n",
    "    connection = engine.connect()\n",
    "    trans = connection.begin()\n",
    "    try:\n",
    "        df.to_sql(table_name, connection, if_exists='replace', index=False)\n",
    "        trans.commit()\n",
    "    except exc.SQLAlchemyError as e:\n",
    "        print(f\"Error loading {table_name}: {e}\")\n",
    "        trans.rollback()\n",
    "    finally:\n",
    "        connection.close()\n",
    "\n",
    "# Save dataframes to the MySQL database\n",
    "load_data_to_mysql(reviews, 'reviews')\n",
    "load_data_to_mysql(artists, 'artists')\n",
    "load_data_to_mysql(content, 'content')\n",
    "load_data_to_mysql(genres, 'genres')\n",
    "load_data_to_mysql(labels, 'labels')\n",
    "load_data_to_mysql(years, 'years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using .cursor() method:\n",
      "('metal box', 'public image ltd', 10.0)\n",
      "('blood on the tracks', 'bob dylan', 10.0)\n",
      "('another green world', 'brian eno', 10.0)\n",
      "('songs in the key of life', 'stevie wonder', 10.0)\n",
      "('in concert', 'nina simone', 10.0)\n",
      "(\"tonight's the night\", 'neil young', 10.0)\n",
      "('hounds of love', 'kate bush', 10.0)\n",
      "('sign \"o\" the times', 'prince', 10.0)\n",
      "('1999', 'prince', 10.0)\n",
      "('purple rain', 'prince, the revolution', 10.0)\n",
      "('dirty mind', 'prince', 10.0)\n",
      "('off the wall', 'michael jackson', 10.0)\n",
      "('\"heroes\"', 'david bowie', 10.0)\n",
      "('low', 'david bowie', 10.0)\n",
      "('a love supreme: the complete masters', 'john coltrane', 10.0)\n",
      "(\"people's instinctive travels and the paths of rhythm\", 'a tribe called quest', 10.0)\n",
      "('astral weeks', 'van morrison', 10.0)\n",
      "('loaded: re-loaded 45th anniversary edition', 'the velvet underground', 10.0)\n",
      "('sticky fingers', 'the rolling stones', 10.0)\n",
      "('it takes a nation of millions to hold us back', 'public enemy', 10.0)\n",
      "('the velvet underground  45th anniversary super deluxe edition', 'the velvet underground', 10.0)\n",
      "('spiderland', 'slint', 10.0)\n",
      "('the infamous', 'mobb deep', 10.0)\n",
      "('white light/white heat', 'the velvet underground', 10.0)\n",
      "('in utero: 20th anniversary edition', 'nirvana', 10.0)\n",
      "('rumours', 'fleetwood mac', 10.0)\n",
      "('illmatic', 'nas', 10.0)\n",
      "('donuts (45 box set)', 'j dilla', 10.0)\n",
      "('voodoo', 'dangelo', 10.0)\n",
      "('the disintegration loops', 'william basinski', 10.0)\n",
      "('liquid swords: chess box deluxe edition', 'gza', 10.0)\n",
      "(\"isn't anything\", 'my bloody valentine', 10.0)\n",
      "('tago mago [40th anniversary edition]', 'can', 10.0)\n",
      "('the smile sessions', 'the beach boys', 10.0)\n",
      "('laughing stock', 'talk talk', 10.0)\n",
      "('nevermind [20th anniversary edition]', 'nirvana', 10.0)\n",
      "('emergency & i [vinyl reissue]', 'the dismemberment plan', 10.0)\n",
      "('my beautiful dark twisted fantasy', 'kanye west', 10.0)\n",
      "('disintegration [deluxe edition]', 'the cure', 10.0)\n",
      "('exile on main st. [deluxe edition]', 'the rolling stones', 10.0)\n",
      "('quarantine the past', 'pavement', 10.0)\n",
      "(\"ladies and gentlemen we are floating in space [collector's editon]\", 'spiritualized', 10.0)\n",
      "('the stone roses', 'the stone roses', 10.0)\n",
      "('the beatles', 'the beatles', 10.0)\n",
      "('abbey road', 'the beatles', 10.0)\n",
      "('rubber soul', 'the beatles', 10.0)\n",
      "('revolver', 'the beatles', 10.0)\n",
      "(\"sgt. pepper's lonely hearts club band\", 'the beatles', 10.0)\n",
      "('magical mystery tour', 'the beatles', 10.0)\n",
      "('stereo box', 'the beatles', 10.0)\n",
      "('kid a: special collectors edition', 'radiohead', 10.0)\n",
      "('reckoning [deluxe edition]', 'r.e.m.', 10.0)\n",
      "('histoire de melody nelson', 'serge gainsbourg', 10.0)\n",
      "(\"paul's boutique\", 'beastie boys', 10.0)\n",
      "('murmur [deluxe edition]', 'r.e.m.', 10.0)\n",
      "(\"otis blue: otis redding sings soul [collector's edition]\", 'otis redding', 10.0)\n",
      "('unknown pleasures', 'joy division', 10.0)\n",
      "('daydream nation: deluxe edition', 'sonic youth', 10.0)\n",
      "('pink flag', 'wire', 10.0)\n",
      "('born to run: 30th anniversary edition', 'bruce springsteen', 10.0)\n",
      "('in the aeroplane over the sea', 'neutral milk hotel', 10.0)\n",
      "('endtroducing... [deluxe edition]', 'dj shadow', 10.0)\n",
      "(\"crooked rain, crooked rain: la's desert origins\", 'pavement', 10.0)\n",
      "('london calling: 25th anniversary legacy edition', 'the clash', 10.0)\n",
      "('music has the right to children', 'boards of canada', 10.0)\n",
      "('live at the apollo [expanded edition]', 'james brown', 10.0)\n",
      "('no thanks!: the 70s punk rebellion', 'various artists', 10.0)\n",
      "('marquee moon', 'television', 10.0)\n",
      "('the ascension', 'glenn branca', 10.0)\n",
      "(\"this year's model\", 'elvis costello & the attractions', 10.0)\n",
      "('yankee hotel foxtrot', 'wilco', 10.0)\n",
      "('source tags and codes', '...and you will know us by the trail of dead', 10.0)\n",
      "('the olatunji concert: the last live recording', 'john coltrane', 10.0)\n",
      "('kid a', 'radiohead', 10.0)\n",
      "('animals', 'pink floyd', 10.0)\n",
      "('i see a darkness', 'bonnie prince billy', 10.0)\n"
     ]
    }
   ],
   "source": [
    "connection = mysql.connector.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password=MYSQL_ROOT_PASSWORD,\n",
    "    database=MYSQL_DATABASE,\n",
    "    port=3306\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT title, artist, score FROM reviews WHERE score=10\")\n",
    "results_cursor = cursor.fetchall()\n",
    "print(\"Results using .cursor() method:\")\n",
    "for row in results_cursor:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results using pd.read_sql_query():\n",
      "                                            title  \\\n",
      "0                                       metal box   \n",
      "1                             blood on the tracks   \n",
      "2                             another green world   \n",
      "3                        songs in the key of life   \n",
      "4                                      in concert   \n",
      "..                                            ...   \n",
      "71                          source tags and codes   \n",
      "72  the olatunji concert: the last live recording   \n",
      "73                                          kid a   \n",
      "74                                        animals   \n",
      "75                               i see a darkness   \n",
      "\n",
      "                                          artist  score  \n",
      "0                               public image ltd   10.0  \n",
      "1                                      bob dylan   10.0  \n",
      "2                                      brian eno   10.0  \n",
      "3                                  stevie wonder   10.0  \n",
      "4                                    nina simone   10.0  \n",
      "..                                           ...    ...  \n",
      "71  ...and you will know us by the trail of dead   10.0  \n",
      "72                                 john coltrane   10.0  \n",
      "73                                     radiohead   10.0  \n",
      "74                                    pink floyd   10.0  \n",
      "75                           bonnie prince billy   10.0  \n",
      "\n",
      "[76 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT title, artist, score FROM reviews WHERE score=10\"\n",
    "results_df = pd.read_sql_query(query, engine)\n",
    "print(\"\\nResults using pd.read_sql_query():\")\n",
    "print(results_df)\n",
    "\n",
    "# Commit changes and close the database\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part c\n",
    "Follow the instructions in the Jupyter notebook for this module to install PostgreSQL and `psycopg2` on your computer. Then import `psycopg2` and do all of the tasks listed for part a using a PostgreSQL database (including commiting changes and closing the database connection). Take steps to hide your password - do not let it display in your notebook. [3 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "load_dotenv()\n",
    "POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "conn = psycopg2.connect(\n",
    "    user='postgres',\n",
    "    password=POSTGRES_PASSWORD,\n",
    "    host='localhost',\n",
    "    port='5432'\n",
    ")\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "try:\n",
    "    cursor.execute('CREATE DATABASE pitchfork_c')\n",
    "except psycopg2.errors.DuplicateDatabase:\n",
    "    cursor.execute('DROP DATABASE pitchfork_c')\n",
    "    cursor.execute('CREATE DATABASE pitchfork_c')\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    user='postgres',\n",
    "    password=POSTGRES_PASSWORD,\n",
    "    host='localhost',\n",
    "    port='5432',\n",
    "    dbname='pitchfork_c'\n",
    ")\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()\n",
    "\n",
    "reviews = pd.read_csv('reviews.csv')\n",
    "artists = pd.read_csv('artists.csv')\n",
    "content = pd.read_csv('content.csv')\n",
    "genres = pd.read_csv('genres.csv')\n",
    "labels = pd.read_csv('labels.csv')\n",
    "years = pd.read_csv('years.csv')\n",
    "\n",
    "dbms = 'postgresql'\n",
    "connector = 'psycopg2'\n",
    "user = 'postgres'\n",
    "password = POSTGRES_PASSWORD\n",
    "host = 'localhost'\n",
    "port = '5432'\n",
    "database = 'pitchfork_c'\n",
    "engine_string = f'{dbms}+{connector}://{user}:{password}@{host}:{port}/{database}'\n",
    "engine = create_engine(engine_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_to_postgresql(df, table_name, chunk_size=1000):\n",
    "    connection = engine.connect()\n",
    "    trans = connection.begin()\n",
    "    try:\n",
    "        for i in range(0, len(df), chunk_size):\n",
    "            df_chunk = df.iloc[i:i+chunk_size]\n",
    "            df_chunk.to_sql(table_name, connection, if_exists='append', index=False)\n",
    "        trans.commit()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {table_name}: {e}\")\n",
    "        trans.rollback()\n",
    "    finally:\n",
    "        connection.close()\n",
    "\n",
    "# Save dataframes to the PostgreSQL database\n",
    "load_data_to_postgresql(reviews, 'reviews')\n",
    "load_data_to_postgresql(artists, 'artists')\n",
    "load_data_to_postgresql(content, 'content')\n",
    "load_data_to_postgresql(genres, 'genres')\n",
    "load_data_to_postgresql(labels, 'labels')\n",
    "load_data_to_postgresql(years, 'years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using .cursor() method:\n",
      "('metal box', 'public image ltd', 10.0)\n",
      "('blood on the tracks', 'bob dylan', 10.0)\n",
      "('another green world', 'brian eno', 10.0)\n",
      "('songs in the key of life', 'stevie wonder', 10.0)\n",
      "('in concert', 'nina simone', 10.0)\n",
      "(\"tonight's the night\", 'neil young', 10.0)\n",
      "('hounds of love', 'kate bush', 10.0)\n",
      "('sign \"o\" the times', 'prince', 10.0)\n",
      "('1999', 'prince', 10.0)\n",
      "('purple rain', 'prince, the revolution', 10.0)\n",
      "('dirty mind', 'prince', 10.0)\n",
      "('off the wall', 'michael jackson', 10.0)\n",
      "('\"heroes\"', 'david bowie', 10.0)\n",
      "('low', 'david bowie', 10.0)\n",
      "('a love supreme: the complete masters', 'john coltrane', 10.0)\n",
      "(\"people's instinctive travels and the paths of rhythm\", 'a tribe called quest', 10.0)\n",
      "('astral weeks', 'van morrison', 10.0)\n",
      "('loaded: re-loaded 45th anniversary edition', 'the velvet underground', 10.0)\n",
      "('sticky fingers', 'the rolling stones', 10.0)\n",
      "('it takes a nation of millions to hold us back', 'public enemy', 10.0)\n",
      "('the velvet underground  45th anniversary super deluxe edition', 'the velvet underground', 10.0)\n",
      "('spiderland', 'slint', 10.0)\n",
      "('the infamous', 'mobb deep', 10.0)\n",
      "('white light/white heat', 'the velvet underground', 10.0)\n",
      "('in utero: 20th anniversary edition', 'nirvana', 10.0)\n",
      "('rumours', 'fleetwood mac', 10.0)\n",
      "('illmatic', 'nas', 10.0)\n",
      "('donuts (45 box set)', 'j dilla', 10.0)\n",
      "('voodoo', 'dangelo', 10.0)\n",
      "('the disintegration loops', 'william basinski', 10.0)\n",
      "('liquid swords: chess box deluxe edition', 'gza', 10.0)\n",
      "(\"isn't anything\", 'my bloody valentine', 10.0)\n",
      "('tago mago [40th anniversary edition]', 'can', 10.0)\n",
      "('the smile sessions', 'the beach boys', 10.0)\n",
      "('laughing stock', 'talk talk', 10.0)\n",
      "('nevermind [20th anniversary edition]', 'nirvana', 10.0)\n",
      "('emergency & i [vinyl reissue]', 'the dismemberment plan', 10.0)\n",
      "('my beautiful dark twisted fantasy', 'kanye west', 10.0)\n",
      "('disintegration [deluxe edition]', 'the cure', 10.0)\n",
      "('exile on main st. [deluxe edition]', 'the rolling stones', 10.0)\n",
      "('quarantine the past', 'pavement', 10.0)\n",
      "(\"ladies and gentlemen we are floating in space [collector's editon]\", 'spiritualized', 10.0)\n",
      "('the stone roses', 'the stone roses', 10.0)\n",
      "('the beatles', 'the beatles', 10.0)\n",
      "('abbey road', 'the beatles', 10.0)\n",
      "('rubber soul', 'the beatles', 10.0)\n",
      "('revolver', 'the beatles', 10.0)\n",
      "(\"sgt. pepper's lonely hearts club band\", 'the beatles', 10.0)\n",
      "('magical mystery tour', 'the beatles', 10.0)\n",
      "('stereo box', 'the beatles', 10.0)\n",
      "('kid a: special collectors edition', 'radiohead', 10.0)\n",
      "('reckoning [deluxe edition]', 'r.e.m.', 10.0)\n",
      "('histoire de melody nelson', 'serge gainsbourg', 10.0)\n",
      "(\"paul's boutique\", 'beastie boys', 10.0)\n",
      "('murmur [deluxe edition]', 'r.e.m.', 10.0)\n",
      "(\"otis blue: otis redding sings soul [collector's edition]\", 'otis redding', 10.0)\n",
      "('unknown pleasures', 'joy division', 10.0)\n",
      "('daydream nation: deluxe edition', 'sonic youth', 10.0)\n",
      "('pink flag', 'wire', 10.0)\n",
      "('born to run: 30th anniversary edition', 'bruce springsteen', 10.0)\n",
      "('in the aeroplane over the sea', 'neutral milk hotel', 10.0)\n",
      "('endtroducing... [deluxe edition]', 'dj shadow', 10.0)\n",
      "(\"crooked rain, crooked rain: la's desert origins\", 'pavement', 10.0)\n",
      "('london calling: 25th anniversary legacy edition', 'the clash', 10.0)\n",
      "('music has the right to children', 'boards of canada', 10.0)\n",
      "('live at the apollo [expanded edition]', 'james brown', 10.0)\n",
      "('no thanks!: the 70s punk rebellion', 'various artists', 10.0)\n",
      "('marquee moon', 'television', 10.0)\n",
      "('the ascension', 'glenn branca', 10.0)\n",
      "(\"this year's model\", 'elvis costello & the attractions', 10.0)\n",
      "('yankee hotel foxtrot', 'wilco', 10.0)\n",
      "('source tags and codes', '...and you will know us by the trail of dead', 10.0)\n",
      "('the olatunji concert: the last live recording', 'john coltrane', 10.0)\n",
      "('kid a', 'radiohead', 10.0)\n",
      "('animals', 'pink floyd', 10.0)\n",
      "('i see a darkness', 'bonnie prince billy', 10.0)\n",
      "\n",
      "Results using pd.read_sql_query():\n",
      "                                            title  \\\n",
      "0                                       metal box   \n",
      "1                             blood on the tracks   \n",
      "2                             another green world   \n",
      "3                        songs in the key of life   \n",
      "4                                      in concert   \n",
      "..                                            ...   \n",
      "71                          source tags and codes   \n",
      "72  the olatunji concert: the last live recording   \n",
      "73                                          kid a   \n",
      "74                                        animals   \n",
      "75                               i see a darkness   \n",
      "\n",
      "                                          artist  score  \n",
      "0                               public image ltd   10.0  \n",
      "1                                      bob dylan   10.0  \n",
      "2                                      brian eno   10.0  \n",
      "3                                  stevie wonder   10.0  \n",
      "4                                    nina simone   10.0  \n",
      "..                                           ...    ...  \n",
      "71  ...and you will know us by the trail of dead   10.0  \n",
      "72                                 john coltrane   10.0  \n",
      "73                                     radiohead   10.0  \n",
      "74                                    pink floyd   10.0  \n",
      "75                           bonnie prince billy   10.0  \n",
      "\n",
      "[76 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SELECT title, artist, score FROM reviews WHERE score=10\")\n",
    "results_cursor = cursor.fetchall()\n",
    "print(\"Results using .cursor() method:\")\n",
    "for row in results_cursor:\n",
    "    print(row)\n",
    "    \n",
    "query = \"SELECT title, artist, score FROM reviews WHERE score=10\"\n",
    "results_df = pd.read_sql_query(query, engine)\n",
    "print(\"\\nResults using pd.read_sql_query():\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "[Colin Mitchell](http://muffinlabs.com/) is a web-developer and artist who has a bunch of [cool projects](http://muffinlabs.com/projects.html) that play with what data can do on the internet. One of his projects is [Today in History](https://history.muffinlabs.com/), which provides an API to access all the Wikipedia pages for historical events that happened on this day in JSON format. The records in this JSON are stored in the `['data']['events']` path. Here's the first listing for today:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': '30 BC',\n",
       " 'text': 'Octavian (later known as Augustus) enters Alexandria, Egypt, bringing it under the control of the Roman Republic.',\n",
       " 'html': '30 BC - 30 BC – <a href=\"https://wikipedia.org/wiki/Augustus\" title=\"Augustus\">Octavian</a> (later known as Augustus) enters <a href=\"https://wikipedia.org/wiki/Alexandria\" title=\"Alexandria\">Alexandria</a>, <a href=\"https://wikipedia.org/wiki/Egypt\" title=\"Egypt\">Egypt</a>, bringing it under the control of the <a href=\"https://wikipedia.org/wiki/Roman_Republic\" title=\"Roman Republic\">Roman Republic</a>.',\n",
       " 'no_year_html': '30 BC – <a href=\"https://wikipedia.org/wiki/Augustus\" title=\"Augustus\">Octavian</a> (later known as Augustus) enters <a href=\"https://wikipedia.org/wiki/Alexandria\" title=\"Alexandria\">Alexandria</a>, <a href=\"https://wikipedia.org/wiki/Egypt\" title=\"Egypt\">Egypt</a>, bringing it under the control of the <a href=\"https://wikipedia.org/wiki/Roman_Republic\" title=\"Roman Republic\">Roman Republic</a>.',\n",
       " 'links': [{'title': 'Augustus',\n",
       "   'link': 'https://wikipedia.org/wiki/Augustus'},\n",
       "  {'title': 'Alexandria', 'link': 'https://wikipedia.org/wiki/Alexandria'},\n",
       "  {'title': 'Egypt', 'link': 'https://wikipedia.org/wiki/Egypt'},\n",
       "  {'title': 'Roman Republic',\n",
       "   'link': 'https://wikipedia.org/wiki/Roman_Republic'}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = requests.get(\"https://history.muffinlabs.com/date\")\n",
    "history_json = json.loads(history.text)\n",
    "events = history_json['data']['Events']\n",
    "events[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, you will use MongoDB and the `pymongo` library to create a local document store NoSQL database containing these historical events.\n",
    "\n",
    "Follow the instructions in the Jupyter notebook for this module to install MongoDB and `pymongo` on your computer. Make sure the local MongoDB server is running. Then import `pymongo`, connect to the local MongoDB client, create a database named \"history\" and a collection within that database named \"today\". Insert all of the records in `events` into this collection. Then issue the following query to find all of the records whose text contain the word \"Virginia\":\n",
    "```\n",
    "query = {\n",
    "    \"text\":{\n",
    "        \"$regex\": 'Virginia'\n",
    "    }\n",
    "}\n",
    "```\n",
    "If there are no results that contain the word \"Virginia\", choose a different work like \"England\" or \"China\". Display the count of the number of documents that match this query, display the output of the query, and generate a JSON formatted variable containing the output. [3 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents containing 'China': 3\n",
      "{'_id': ObjectId('66ab3d1d01612a1b91f1d2b7'), 'year': '607', 'text': 'Ono no Imoko is dispatched as envoy to the Sui court in China (Traditional Japanese date: July 3, 607).', 'html': '607 - <a href=\"https://wikipedia.org/wiki/Ono_no_Imoko\" title=\"Ono no Imoko\">Ono no Imoko</a> is dispatched as envoy to the <a href=\"https://wikipedia.org/wiki/Sui_dynasty\" title=\"Sui dynasty\">Sui</a> court in China (Traditional <a href=\"https://wikipedia.org/wiki/Japanese_calendar\" title=\"Japanese calendar\">Japanese date</a>: July 3, 607).', 'no_year_html': '<a href=\"https://wikipedia.org/wiki/Ono_no_Imoko\" title=\"Ono no Imoko\">Ono no Imoko</a> is dispatched as envoy to the <a href=\"https://wikipedia.org/wiki/Sui_dynasty\" title=\"Sui dynasty\">Sui</a> court in China (Traditional <a href=\"https://wikipedia.org/wiki/Japanese_calendar\" title=\"Japanese calendar\">Japanese date</a>: July 3, 607).', 'links': [{'title': 'Ono no Imoko', 'link': 'https://wikipedia.org/wiki/Ono_no_Imoko'}, {'title': 'Sui dynasty', 'link': 'https://wikipedia.org/wiki/Sui_dynasty'}, {'title': 'Japanese calendar', 'link': 'https://wikipedia.org/wiki/Japanese_calendar'}]}\n",
      "{'_id': ObjectId('66ab3d1d01612a1b91f1d2ce'), 'year': '1894', 'text': 'The Empire of Japan and Qing China declare war on each other after a week of fighting over Korea, formally inaugurating the First Sino-Japanese War.', 'html': '1894 - The <a href=\"https://wikipedia.org/wiki/Empire_of_Japan\" title=\"Empire of Japan\">Empire of Japan</a> and <a href=\"https://wikipedia.org/wiki/Qing_dynasty\" title=\"Qing dynasty\">Qing China</a> declare war on each other after a week of fighting over Korea, formally inaugurating the <a href=\"https://wikipedia.org/wiki/First_Sino-Japanese_War\" title=\"First Sino-Japanese War\">First Sino-Japanese War</a>.', 'no_year_html': 'The <a href=\"https://wikipedia.org/wiki/Empire_of_Japan\" title=\"Empire of Japan\">Empire of Japan</a> and <a href=\"https://wikipedia.org/wiki/Qing_dynasty\" title=\"Qing dynasty\">Qing China</a> declare war on each other after a week of fighting over Korea, formally inaugurating the <a href=\"https://wikipedia.org/wiki/First_Sino-Japanese_War\" title=\"First Sino-Japanese War\">First Sino-Japanese War</a>.', 'links': [{'title': 'Empire of Japan', 'link': 'https://wikipedia.org/wiki/Empire_of_Japan'}, {'title': 'Qing dynasty', 'link': 'https://wikipedia.org/wiki/Qing_dynasty'}, {'title': 'First Sino-Japanese War', 'link': 'https://wikipedia.org/wiki/First_Sino-Japanese_War'}]}\n",
      "{'_id': ObjectId('66ab3d1d01612a1b91f1d2e3'), 'year': '1966', 'text': 'Purges of intellectuals and imperialists becomes official China policy at the beginning of the Cultural Revolution.', 'html': '1966 - Purges of intellectuals and imperialists becomes official China policy at the beginning of the <a href=\"https://wikipedia.org/wiki/Cultural_Revolution\" title=\"Cultural Revolution\">Cultural Revolution</a>.', 'no_year_html': 'Purges of intellectuals and imperialists becomes official China policy at the beginning of the <a href=\"https://wikipedia.org/wiki/Cultural_Revolution\" title=\"Cultural Revolution\">Cultural Revolution</a>.', 'links': [{'title': 'Cultural Revolution', 'link': 'https://wikipedia.org/wiki/Cultural_Revolution'}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "from bson.json_util import dumps, loads\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "history = requests.get(\"https://history.muffinlabs.com/date\")\n",
    "history_json = json.loads(history.text)\n",
    "events = history_json['data']['Events']\n",
    "\n",
    "mongo_username = os.getenv('MONGO_INITDB_ROOT_USERNAME')\n",
    "mongo_password = os.getenv('MONGO_INITDB_ROOT_PASSWORD')\n",
    "mongo_host = os.getenv('MONGO_HOST', 'localhost')\n",
    "mongo_port = os.getenv('MONGO_PORT', '27017')\n",
    "\n",
    "mongo_url = f\"mongodb://{mongo_username}:{mongo_password}@{mongo_host}:{mongo_port}/\"\n",
    "\n",
    "client = MongoClient(mongo_url)\n",
    "history_db = client[\"history\"]\n",
    "collist = history_db.list_collection_names()\n",
    "if \"today\" in collist:\n",
    "    history_db.today.drop()\n",
    "\n",
    "today_collection = history_db[\"today\"]\n",
    "today_collection.insert_many(events)\n",
    "query = {\"text\": {\"$regex\": 'China'}}\n",
    "results = today_collection.find(query)\n",
    "\n",
    "\n",
    "count = today_collection.count_documents(query)\n",
    "print(f\"Number of documents containing 'China': {count}\")\n",
    "for doc in results:\n",
    "    print(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 [No points, no need to write anything here, but do it anyway!]\n",
    "When you are done working, go to the same terminal window you used to launch the databases with `docker compose up`. Here, type CONTROL + C on your keyboard to shut down the container.\n",
    "\n",
    "Next type\n",
    "```\n",
    "docker compose down\n",
    "```\n",
    "This step removes extra database software, networks, volumes, etc. running on your computer. If you don't need them, don't clog your computer.\n",
    "\n",
    "Whenever you need to work with databases, return to the terminal, navigate to this folder and type\n",
    "```\n",
    "docker compose up\n",
    "```\n",
    "to bring all these resources back online. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
